wandb_version: 1

CRate:
  desc: null
  value: 8
_wandb:
  desc: null
  value:
    cli_version: 0.12.7
    framework: huggingface
    huggingface_version: 1.1.1
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.8.12
    start_time: 1643259893
    t:
      1:
      - 1
      - 5
      - 11
      2:
      - 1
      - 5
      - 11
      3:
      - 1
      4: 3.8.12
      5: 0.12.7
      6: 1.1.1
      8:
      - 5
adapter_layers:
  desc: null
  value: null
adapter_names:
  desc: null
  value: entity_predict--amp
amp:
  desc: null
  value: false
batch_size:
  desc: null
  value: 64
bi_direction:
  desc: null
  value: false
cache_token_encodings:
  desc: null
  value: false
cuda:
  desc: null
  value: true
device:
  desc: null
  value: cuda
epochs:
  desc: null
  value: 2
gradient_accumulation_steps:
  desc: null
  value: 1
input_dir:
  desc: null
  value: /home/simon/wikidata5m
is_hierarchical:
  desc: null
  value: false
is_multilabel:
  desc: null
  value: false
lr:
  desc: null
  value: 0.0001
max_seq_length:
  desc: null
  value: 64
model:
  desc: null
  value: roberta-base
model_str:
  desc: null
  value: roberta-base_20220127_130456_adapter
n_gpu:
  desc: null
  value: 1
n_partition:
  desc: null
  value: 10
non_sequential:
  desc: null
  value: true
num_workers:
  desc: null
  value: 32
output_dir:
  desc: null
  value: checkpoints
patience:
  desc: null
  value: 5
save_path:
  desc: null
  value: checkpoints/roberta-base_20220127_130456_adapter
save_step:
  desc: null
  value: 2000
seed:
  desc: null
  value: 1643259896
shuffle_rate:
  desc: null
  value: null
sub_group_idx:
  desc: null
  value: null
subset:
  desc: null
  value: 1.0
tokenizer:
  desc: null
  value: roberta-base
trained_model:
  desc: null
  value: null
use_adapter:
  desc: null
  value: true
warmup_proportion:
  desc: null
  value: 0.1
